{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab5edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 14200 records.\n",
      "       Ticker    close                 date    high      low    month    open  \\\n",
      "0        SBIN   602.95  2023-10-03 05:30:00   604.9   589.60  2023-10   596.6   \n",
      "1  BAJFINANCE  7967.60  2023-10-03 05:30:00  7975.5  7755.00  2023-10  7780.8   \n",
      "2       TITAN  3196.25  2023-10-03 05:30:00  3212.5  3114.40  2023-10  3148.8   \n",
      "3         ITC   439.75  2023-10-03 05:30:00   442.9   439.25  2023-10   441.0   \n",
      "4         TCS  3513.85  2023-10-03 05:30:00  3534.2  3480.10  2023-10  3534.2   \n",
      "\n",
      "     volume  \n",
      "0  15322196  \n",
      "1    944555  \n",
      "2   1007308  \n",
      "3   7481883  \n",
      "4   1948148  \n",
      "Total rows: 14200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def combine_yaml_from_nested_folders(parent_folder):\n",
    "    data_list = []\n",
    "\n",
    "    # Walk through all subdirectories and files\n",
    "    for root, _, files in os.walk(parent_folder):\n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith(('.yaml', '.yml')):  # include both extensions\n",
    "                file_path = os.path.join(root, file_name)\n",
    "\n",
    "                # Read the YAML file\n",
    "                with open(file_path, 'r', encoding='utf-8') as yfile:\n",
    "                    yaml_data = yaml.safe_load(yfile)\n",
    "\n",
    "                    # Check if YAML data exists\n",
    "                    if yaml_data is None:\n",
    "                        continue\n",
    "\n",
    "                    # Flatten dicts or lists of dicts\n",
    "                    if isinstance(yaml_data, dict):\n",
    "                        data_list.append(yaml_data)\n",
    "                    elif isinstance(yaml_data, list):\n",
    "                        # Flatten nested dicts if needed\n",
    "                        for item in yaml_data:\n",
    "                            if isinstance(item, dict):\n",
    "                                data_list.append(item)\n",
    "\n",
    "    # Convert the combined list of dictionaries to a DataFrame\n",
    "    if data_list:\n",
    "        dataframe = pd.DataFrame(data_list)\n",
    "        print(f\"✅ Found {len(data_list)} records.\")\n",
    "    else:\n",
    "        dataframe = pd.DataFrame()\n",
    "        print(\"⚠️ No data found in YAML files.\")\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "# Correct parent folder\n",
    "parent_folder = r\"D:\\Py_start\\Python\\project_SN\\DDSA\\Data-20251214T163409Z-3-001\\Data\\data\"\n",
    "\n",
    "# Combine YAML files\n",
    "df = combine_yaml_from_nested_folders(parent_folder)\n",
    "\n",
    "# Save to CSV or display\n",
    "output_csv = r\"D:\\Py_start\\Python\\project_SN\\DDSA\\new\\combined_data.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(df.head())\n",
    "print(\"Total rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a557d960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Ticker'].unique().tolist()) #length of unique tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b90cd717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Nifty50\\ADANIENT.csv\n",
      "Saved: Nifty50\\ADANIPORTS.csv\n",
      "Saved: Nifty50\\APOLLOHOSP.csv\n",
      "Saved: Nifty50\\ASIANPAINT.csv\n",
      "Saved: Nifty50\\AXISBANK.csv\n",
      "Saved: Nifty50\\BAJAJ-AUTO.csv\n",
      "Saved: Nifty50\\BAJAJFINSV.csv\n",
      "Saved: Nifty50\\BAJFINANCE.csv\n",
      "Saved: Nifty50\\BEL.csv\n",
      "Saved: Nifty50\\BHARTIARTL.csv\n",
      "Saved: Nifty50\\BPCL.csv\n",
      "Saved: Nifty50\\BRITANNIA.csv\n",
      "Saved: Nifty50\\CIPLA.csv\n",
      "Saved: Nifty50\\COALINDIA.csv\n",
      "Saved: Nifty50\\DRREDDY.csv\n",
      "Saved: Nifty50\\EICHERMOT.csv\n",
      "Saved: Nifty50\\GRASIM.csv\n",
      "Saved: Nifty50\\HCLTECH.csv\n",
      "Saved: Nifty50\\HDFCBANK.csv\n",
      "Saved: Nifty50\\HDFCLIFE.csv\n",
      "Saved: Nifty50\\HEROMOTOCO.csv\n",
      "Saved: Nifty50\\HINDALCO.csv\n",
      "Saved: Nifty50\\HINDUNILVR.csv\n",
      "Saved: Nifty50\\ICICIBANK.csv\n",
      "Saved: Nifty50\\INDUSINDBK.csv\n",
      "Saved: Nifty50\\INFY.csv\n",
      "Saved: Nifty50\\ITC.csv\n",
      "Saved: Nifty50\\JSWSTEEL.csv\n",
      "Saved: Nifty50\\KOTAKBANK.csv\n",
      "Saved: Nifty50\\LT.csv\n",
      "Saved: Nifty50\\M&M.csv\n",
      "Saved: Nifty50\\MARUTI.csv\n",
      "Saved: Nifty50\\NESTLEIND.csv\n",
      "Saved: Nifty50\\NTPC.csv\n",
      "Saved: Nifty50\\ONGC.csv\n",
      "Saved: Nifty50\\POWERGRID.csv\n",
      "Saved: Nifty50\\RELIANCE.csv\n",
      "Saved: Nifty50\\SBILIFE.csv\n",
      "Saved: Nifty50\\SBIN.csv\n",
      "Saved: Nifty50\\SHRIRAMFIN.csv\n",
      "Saved: Nifty50\\SUNPHARMA.csv\n",
      "Saved: Nifty50\\TATACONSUM.csv\n",
      "Saved: Nifty50\\TATAMOTORS.csv\n",
      "Saved: Nifty50\\TATASTEEL.csv\n",
      "Saved: Nifty50\\TCS.csv\n",
      "Saved: Nifty50\\TECHM.csv\n",
      "Saved: Nifty50\\TITAN.csv\n",
      "Saved: Nifty50\\TRENT.csv\n",
      "Saved: Nifty50\\ULTRACEMCO.csv\n",
      "Saved: Nifty50\\WIPRO.csv\n"
     ]
    }
   ],
   "source": [
    "def save_stocks_to_csv(dataframe, output_folder):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Group the DataFrame by stock name\n",
    "    grouped = dataframe.groupby('Ticker')  \n",
    "\n",
    "    for stock_name, stock_data in grouped:\n",
    "        # Define the output file path\n",
    "        file_name = f\"{stock_name}.csv\"\n",
    "        file_path = os.path.join(output_folder, file_name)\n",
    "        \n",
    "        # Save the stock data to a CSV file\n",
    "        stock_data.to_csv(file_path, index=False)\n",
    "        print(f\"Saved: {file_path}\")\n",
    "\n",
    "# Example Usage\n",
    "# Assuming you already have a DataFrame named df with a column 'StockName'\n",
    "output_directory = 'Nifty50'  # Directory to save CSV files\n",
    "save_stocks_to_csv(df, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
